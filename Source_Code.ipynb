{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW-kYCdmPBqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6acedf0f-b2c5-4990-e4f1-44ad1388c8ff"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer,LancasterStemmer, SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "porter = PorterStemmer()\n",
        "Lancaster = LancasterStemmer()\n",
        "snowball= SnowballStemmer('english')\n",
        "wordnet = WordNetLemmatizer() \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rjdmYUDPD5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "df0 = pd.read_csv(url, sep=\"\\t\")\n",
        "numSentences = df0['SentenceId'].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59H1csJNPHM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ea6531c8-5634-478d-b889-7ce82fb25d24"
      },
      "source": [
        "df0.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRHSHpiWZP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "9d3db0db-1672-42fa-a3d8-55786588ad4f"
      },
      "source": [
        "sample0 = df0.sample(frac=1)\n",
        "sample0.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42806</th>\n",
              "      <td>42807</td>\n",
              "      <td>2065</td>\n",
              "      <td>the images</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120495</th>\n",
              "      <td>120496</td>\n",
              "      <td>6442</td>\n",
              "      <td>it does n't disappoint .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97490</th>\n",
              "      <td>97491</td>\n",
              "      <td>5098</td>\n",
              "      <td>post , pre</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150578</th>\n",
              "      <td>150579</td>\n",
              "      <td>8206</td>\n",
              "      <td>when the TV cow is free</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33001</th>\n",
              "      <td>33002</td>\n",
              "      <td>1546</td>\n",
              "      <td>Ray</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15380</th>\n",
              "      <td>15381</td>\n",
              "      <td>658</td>\n",
              "      <td>pity and sympathy</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136550</th>\n",
              "      <td>136551</td>\n",
              "      <td>7383</td>\n",
              "      <td>with ambitious , eager first-time filmmakers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155992</th>\n",
              "      <td>155993</td>\n",
              "      <td>8540</td>\n",
              "      <td>to go with this claustrophobic concept</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53354</th>\n",
              "      <td>53355</td>\n",
              "      <td>2647</td>\n",
              "      <td>comic set</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137617</th>\n",
              "      <td>137618</td>\n",
              "      <td>7445</td>\n",
              "      <td>has nothing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...  Sentiment\n",
              "42806      42807  ...          2\n",
              "120495    120496  ...          3\n",
              "97490      97491  ...          2\n",
              "150578    150579  ...          2\n",
              "33001      33002  ...          2\n",
              "15380      15381  ...          2\n",
              "136550    136551  ...          3\n",
              "155992    155993  ...          1\n",
              "53354      53355  ...          3\n",
              "137617    137618  ...          1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ROi0EfxhUs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.DataFrame(df0, columns=['Phrase', 'Sentiment'])\n",
        "# Splits the dataset so 70% is used for training and 30% for testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(all_data['Phrase'], all_data['Sentiment'], test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFJ_mvvXr5si",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1a1a19cb-e10b-45b0-be40-5f4ccaa180a8"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113967    The Irwins ' scenes are fascinating ; the movi...\n",
              "90853                                       never quite gel\n",
              "152915    look behind the curtain that separates comics ...\n",
              "140498    that has bucked the odds to emerge as an exqui...\n",
              "120920                                  of dramatic urgency\n",
              "                                ...                        \n",
              "28717                as a serious drama about spousal abuse\n",
              "135995    The elements were all there but lack of a pysc...\n",
              "48948                                             routinely\n",
              "91131     to films which will cause loads of irreparable...\n",
              "17222                                                 lower\n",
              "Name: Phrase, Length: 46818, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRYmIQFthUa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e6e6fc26-16ec-42a8-9ffb-9e8a39bb7603"
      },
      "source": [
        "train = pd.DataFrame(list(zip(x_train, y_train)), columns=['Phrase','Sentiment'])\n",
        "test = pd.DataFrame(list(zip(x_test, y_test)), columns=['Phrase','Sentiment'])\n",
        "print(train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   Phrase  Sentiment\n",
            "0                      half-hearted paeans to empowerment          2\n",
            "1                                               composure          2\n",
            "2                                        recognize it and          2\n",
            "3       children 's entertainment , superhero comics ,...          2\n",
            "4                         see what the director does next          2\n",
            "...                                                   ...        ...\n",
            "109237                                        a solid job          2\n",
            "109238                                 John Hughes comedy          3\n",
            "109239         maintaining consciousness just long enough          1\n",
            "109240  for conveying the way tiny acts of kindness ma...          3\n",
            "109241                      with the titillating material          3\n",
            "\n",
            "[109242 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfpQF_W-WSj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "#convert data into format for the previous labs\n",
        "\n",
        "#use full dataset\n",
        "for i in range(train.shape[0]):\n",
        " tmpWords = word_tokenize(train['Phrase'][i])\n",
        " documents.append((tmpWords, train['Sentiment'][i]))\n",
        "\n",
        "# Use only complete sentences\n",
        "# for i in range(fullSentDf.shape[0]):\n",
        "#   tmpWords = word_tokenize(fullSentDf['Phrase'][i])\n",
        "#   documents.append((tmpWords, fullSentDf['Sentiment'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTIfImaQ1nS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa13b13f-21ab-4063-c3db-20d4168cc0ba"
      },
      "source": [
        "random.seed(9001)\n",
        "random.shuffle(documents)\n",
        "print(documents[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['Snipes', 'relies', 'too', 'much', 'on', 'a', 'scorchingly', 'plotted', 'dramatic', 'scenario', 'for', 'its', 'own', 'good', '.'], 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTiDPhKYQ3rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a0ae42f-4970-4310-f36e-831caafc036d"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = True\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "\n",
        "for l in range(len(documents)):\n",
        "  label = documents[l][1]\n",
        "  tmpReview = []\n",
        "  for w in documents[l][0]:\n",
        "    newWord = w\n",
        "    if remove_stopwords and (w in stopwords_en):\n",
        "      continue\n",
        "    if removePuncs and (w in punctuations):\n",
        "      continue\n",
        "    if useStemming:\n",
        "      newWord = porter.stem(newWord)\n",
        "      # newWord = lancaster.stem(newWord)\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord)\n",
        "  documents[l] = (' '.join(tmpReview), label)\n",
        "print(documents[2])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('frustrat reward', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCDZnmbUnCOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.DataFrame(documents, columns=['Phrase', 'Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt4-N9dfkwiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "876d5d51-fd0b-47f0-af68-c5927f34c196"
      },
      "source": [
        "all_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>brutal clueless</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>snipe reli much scorchingli plot dramat scenar...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frustrat reward</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you feel good feel sad feel piss</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flood</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109237</th>\n",
              "      <td>detail condens</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109238</th>\n",
              "      <td>ke burstein</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109239</th>\n",
              "      <td>advis take warn liter log someth user-friendli</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109240</th>\n",
              "      <td>pretti convinc perform</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109241</th>\n",
              "      <td>feel bunch strung-togeth TV episod</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>109242 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Phrase  Sentiment\n",
              "0                                         brutal clueless          1\n",
              "1       snipe reli much scorchingli plot dramat scenar...          2\n",
              "2                                         frustrat reward          2\n",
              "3                        you feel good feel sad feel piss          3\n",
              "4                                                   flood          2\n",
              "...                                                   ...        ...\n",
              "109237                                     detail condens          2\n",
              "109238                                        ke burstein          2\n",
              "109239     advis take warn liter log someth user-friendli          1\n",
              "109240                             pretti convinc perform          4\n",
              "109241                 feel bunch strung-togeth TV episod          1\n",
              "\n",
              "[109242 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlfDl_BMXjGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features = 10000, stop_words=\"english\", ngram_range=(1,2))\n",
        "\n",
        "x_train = vectorizer.fit_transform(all_data[\"Phrase\"])\n",
        "y_train=all_data[\"Sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ2R5Yrflxh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vectorizer.fit_transform(all_data[\"Phrase\"])\n",
        "Y = all_data['Sentiment']\n",
        "\n",
        "x_train_np = x_train.toarray()\n",
        "y_train_np=np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gbhwkVxogAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "cc204a29-d9f7-40e2-cb65-866b648ad76c"
      },
      "source": [
        "print(x_train_np.shape)\n",
        "print(y_train_np.shape)\n",
        "print(all_data.Sentiment.value_counts())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242, 10000)\n",
            "(109242,)\n",
            "2    55696\n",
            "3    23037\n",
            "1    19103\n",
            "4     6422\n",
            "0     4984\n",
            "Name: Sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOZCjSWNrJzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pytorch library\n",
        "import torch\n",
        "# Import the 1D convolution layer \n",
        "from torch.nn import Conv1d\n",
        "# Import the max pooling layer\n",
        "from torch.nn import MaxPool1d\n",
        "# Import the flatten layer\n",
        "from torch.nn import Flatten\n",
        "# Import the linear layer\n",
        "from torch.nn import Linear\n",
        "# Import the ReLU activation function\n",
        "from torch.nn.functional import relu, softmax, sigmoid\n",
        "# Import the DataLoader and TensorDataset libraries from PyTorch to work with our datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuMv7sf2rbUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our class MUST be a subclass of torch.nn.Module\n",
        "class CnnClassifier(torch.nn.Module):\n",
        "# Define the initialization method\n",
        "  def __init__(self, batch_size, inputs, outputs):\n",
        "  # Initialize the superclass and store the parameters\n",
        "    super(CnnClassifier, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    # Define the input layer\n",
        "    # (input channels, output channels, kernel size)\n",
        "    self.input_layer = Conv1d(inputs, batch_size, 1) # Define a max pooling layer\n",
        "    # (kernel size)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "\n",
        "    self.conv_layer0 = Conv1d(batch_size, 32, 1)\n",
        "    self.max_pooling_layer0 = MaxPool1d(1)\n",
        "\n",
        "    self.conv_layer1 = Conv1d(32, 64, 1)\n",
        "    self.max_pooling_layer1 = MaxPool1d(1)\n",
        "\n",
        "    self.conv_layer2 = Conv1d(64, 128, 1)\n",
        "    self.max_pooling_layer2 = MaxPool1d(1)\n",
        "\n",
        "\n",
        "    # Define a flatten layer\n",
        "    self.flatten_layer = Flatten()\n",
        "    # Define a linear layer\n",
        "    # (inputs, outputs)\n",
        "    self.linear_layer = Linear(128, 64) # Finally, define the output layer\n",
        "    self.output_layer = Linear(64, outputs)\n",
        "    # Add a sigmoid layer to get a value between 0 and 1\n",
        "    # self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "  # Define a method to feed inputs through the model\n",
        "\n",
        "  def feed(self, input):\n",
        "  # Reshape the entry so it can be fed to the input layer\n",
        "  # Although we’re using 1D convolution, it still expects a 3D array to process in a 1D fashion\n",
        "    input = input.reshape((self.batch_size, self.inputs, 1))\n",
        "    # Get the output of the first layer and run it through the\n",
        "    # the ReLU activation function\n",
        "    output = relu(self.input_layer(input))\n",
        "    # Get the output of the max pooling layer\n",
        "    output = self.max_pooling_layer(output)\n",
        "    # Get the output of the second convolution layer and run it\n",
        "    # through the ReLU activation function\n",
        "    \n",
        "    output = relu(self.conv_layer0(output))\n",
        "    output = self.max_pooling_layer0(output)\n",
        "\n",
        "    output = relu(self.conv_layer1(output))\n",
        "    output = self.max_pooling_layer1(output)\n",
        "\n",
        "    output = relu(self.conv_layer2(output))\n",
        "    output = self.max_pooling_layer2(output)\n",
        "    \n",
        "    # Get the output of the flatten layer\n",
        "    output = self.flatten_layer(output)\n",
        "    # Get the output of the linear layer and run it through the\n",
        "    # ReLU activation function\n",
        "    output = self.linear_layer(output)\n",
        "    # Finally, get the output of the output layer and return it\n",
        "    output = self.output_layer(output)\n",
        "    #We get a float value between 0 and 1 for our binary classifier and loss function\n",
        "    # output = sigmoid(output)\n",
        "    #We return another variable with output of integer 0 or 1, for accuracy & F-score\n",
        "    output_ = torch.round(output)\n",
        "    output = softmax(output)\n",
        "    #We can also try using softmax instead of or in conjunction with the sigmoid\n",
        "    #output = softmax(output)\n",
        "    return output, output_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YuzqhpNrdig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "799bc6c9-dff5-4dc1-a228-9e8da3d27398"
      },
      "source": [
        "# Import the SGD (stochastic gradient descent) package from pytorch for\n",
        "# our optimizer\n",
        "from torch.optim import Adam, Adamax\n",
        "# Import the L1Loss (mean absolute error loss) package from pytorch for\n",
        "# our performance measure\n",
        "from torch.nn import L1Loss\n",
        "# Import accuracy, precision & recall score package from pytorch's ignite for our score measure\n",
        "# This package is not installed by default so the next line does that\n",
        "!pip install pytorch-ignite\n",
        "from ignite.metrics import Accuracy, Recall, Precision\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Define the batch size we'd like to use\n",
        "batch_size = 128 # (batch size, X columns, Y columns)\n",
        "model = CnnClassifier(batch_size, x_train.shape[1], 5) # Set the model to use the GPU for processing\n",
        "model.cuda()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnClassifier(\n",
              "  (input_layer): Conv1d(10000, 128, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer0): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten_layer): Flatten()\n",
              "  (linear_layer): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQ2BpCbrfXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_loss(model, dataset, train = False, optimizer = None):\n",
        "  # Cycle through the batches and get the average L1 loss\n",
        "  performance = CrossEntropyLoss()\n",
        "  \n",
        "  avg_accu = 0;\n",
        "  avg_rec = 0\n",
        "  avg_prec = 0\n",
        "  avg_loss = 0\n",
        "  count = 0\n",
        "  for input, output in iter(dataset):\n",
        "    \n",
        "    # Get the model's predictions for the training dataset\n",
        "    predictions, predictions_ = model.feed(input) # Get the model's loss using the float returned variable\n",
        "\n",
        "    z=[]\n",
        "    out = output.data.cpu().numpy()\n",
        "    for o in out:\n",
        "      z.append(int(o[0]))\n",
        "\n",
        "    pred, indices = torch.max(predictions,1)\n",
        "\n",
        "    a_list = torch.FloatTensor(z).cuda().long()\n",
        "\n",
        "\n",
        "    loss = performance(predictions, a_list)\n",
        "    # Get the model's performance metrices using the binary returned output\n",
        "    \n",
        "    tmp_accu = accuracy_score(z, indices.data.cpu())\n",
        "    tmp_prec = recall_score(z, indices.data.cpu(), average='macro')\n",
        "    tmp_rec = precision_score(z, indices.data.cpu(), average='macro')\n",
        "    if(train):\n",
        "      # Clear any errors so they don't cummulate\n",
        "      optimizer.zero_grad()\n",
        "      # Compute the gradients for our optimizer\n",
        "      loss.backward()\n",
        "      # Use the optimizer to update the model's parameters based on the gradients\n",
        "      optimizer.step()\n",
        "    # Store the loss and update the counter\n",
        "    avg_loss += loss.item()\n",
        "    # Accumulate performance metrices\n",
        "    avg_accu += tmp_accu\n",
        "    avg_prec += tmp_prec\n",
        "    avg_rec += tmp_rec\n",
        "    count += 1\n",
        "  return avg_loss / count, avg_accu / count, avg_prec / count, avg_rec / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c66a02d4-e4d1-45c5-ac92-e02f0cc8baea",
        "id": "TMB27oXY0Puf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the number of epochs to train for\n",
        "epochs = 35\n",
        "e1=[]\n",
        "a1=[]\n",
        "l1=[]\n",
        "f1plot=[]\n",
        "# Define the performance measure and optimizer\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#optimizer = Adam(model.parameters())\n",
        "# Convert the training set into torch variables for our model using the GPU\n",
        "# as floats. The reshape is to remove a warning pytorch outputs otherwise.\n",
        "inputs = torch.from_numpy(x_train_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_train_np.reshape(y_train_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "# Create a DataLoader instance to work with our batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True) # Start the training loop\n",
        "for epoch in range(epochs):\n",
        "  e1.append(epoch+1)\n",
        "  # Cycle through the batches and get the average loss\n",
        "  avg_loss, avg_accu, avg_prec, avg_rec = model_loss(model, loader, train=True, optimizer=optimizer)\n",
        "  f1 = (2*(avg_prec*avg_rec)/(avg_prec + avg_rec)) #calculate the f1 score\n",
        "  a1.append(avg_accu)\n",
        "  l1.append(avg_loss)\n",
        "  f1plot.append(f1)\n",
        "  # Output the average loss & performance metrices\n",
        "  print(\"Epoch \" + str(epoch + 1) + \":\\n\\tLoss = \" + str(avg_loss) + \"\\n\\tAccuracy = \" + str(avg_accu) + \"\\n\\tF1 Score = \" + str(f1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "\tLoss = 1.371223022761686\n",
            "\tAccuracy = 0.5339243845252052\n",
            "\tF1 Score = 0.19333222842086373\n",
            "Epoch 2:\n",
            "\tLoss = 1.3089650796697958\n",
            "\tAccuracy = 0.592266266119578\n",
            "\tF1 Score = 0.28858095217693835\n",
            "Epoch 3:\n",
            "\tLoss = 1.2735491037927786\n",
            "\tAccuracy = 0.628810082063306\n",
            "\tF1 Score = 0.3527270513941692\n",
            "Epoch 4:\n",
            "\tLoss = 1.2572624744871437\n",
            "\tAccuracy = 0.6453967614302462\n",
            "\tF1 Score = 0.3674094738131739\n",
            "Epoch 5:\n",
            "\tLoss = 1.2475336314924717\n",
            "\tAccuracy = 0.6555539273153576\n",
            "\tF1 Score = 0.37698635600533564\n",
            "Epoch 6:\n",
            "\tLoss = 1.2393503254770812\n",
            "\tAccuracy = 0.6640625\n",
            "\tF1 Score = 0.4206411528750301\n",
            "Epoch 7:\n",
            "\tLoss = 1.230581185742252\n",
            "\tAccuracy = 0.672809202813599\n",
            "\tF1 Score = 0.48375694164409433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8:\n",
            "\tLoss = 1.2219260489395607\n",
            "\tAccuracy = 0.6818123534583822\n",
            "\tF1 Score = 0.5247723051401418\n",
            "Epoch 9:\n",
            "\tLoss = 1.2149513625875028\n",
            "\tAccuracy = 0.6888280334114889\n",
            "\tF1 Score = 0.548153450242451\n",
            "Epoch 10:\n",
            "\tLoss = 1.2082529230106618\n",
            "\tAccuracy = 0.6957429660023446\n",
            "\tF1 Score = 0.5678133406268965\n",
            "Epoch 11:\n",
            "\tLoss = 1.202923831179441\n",
            "\tAccuracy = 0.7011466881594373\n",
            "\tF1 Score = 0.5852560264294798\n",
            "Epoch 12:\n",
            "\tLoss = 1.2001729148493563\n",
            "\tAccuracy = 0.704059202813599\n",
            "\tF1 Score = 0.5903719140096167\n",
            "Epoch 13:\n",
            "\tLoss = 1.197509955409543\n",
            "\tAccuracy = 0.7067793815943728\n",
            "\tF1 Score = 0.5970353642201734\n",
            "Epoch 14:\n",
            "\tLoss = 1.1951957161233686\n",
            "\tAccuracy = 0.7090416178194607\n",
            "\tF1 Score = 0.6040571623832459\n",
            "Epoch 15:\n",
            "\tLoss = 1.1928873524716144\n",
            "\tAccuracy = 0.7115694607268465\n",
            "\tF1 Score = 0.6046107590608931\n",
            "Epoch 16:\n",
            "\tLoss = 1.1912332421031115\n",
            "\tAccuracy = 0.7132546893317703\n",
            "\tF1 Score = 0.6093033169667674\n",
            "Epoch 17:\n",
            "\tLoss = 1.188937403811939\n",
            "\tAccuracy = 0.7155077667057445\n",
            "\tF1 Score = 0.6142885214730954\n",
            "Epoch 18:\n",
            "\tLoss = 1.1870248625175055\n",
            "\tAccuracy = 0.7174677608440797\n",
            "\tF1 Score = 0.6189909787831359\n",
            "Epoch 19:\n",
            "\tLoss = 1.1865168577900804\n",
            "\tAccuracy = 0.7180172919109027\n",
            "\tF1 Score = 0.6200056954696712\n",
            "Epoch 20:\n",
            "\tLoss = 1.18507576198399\n",
            "\tAccuracy = 0.719363643024619\n",
            "\tF1 Score = 0.6189406702030411\n",
            "Epoch 21:\n",
            "\tLoss = 1.183682170730403\n",
            "\tAccuracy = 0.7208199003516998\n",
            "\tF1 Score = 0.6251492367797218\n",
            "Epoch 22:\n",
            "\tLoss = 1.1822079700993207\n",
            "\tAccuracy = 0.7222944753810082\n",
            "\tF1 Score = 0.6245508612664756\n",
            "Epoch 23:\n",
            "\tLoss = 1.182541344537545\n",
            "\tAccuracy = 0.7219647567409144\n",
            "\tF1 Score = 0.6248651168602747\n",
            "Epoch 24:\n",
            "\tLoss = 1.1819571557106474\n",
            "\tAccuracy = 0.722688305978898\n",
            "\tF1 Score = 0.6284835845624059\n",
            "Epoch 25:\n",
            "\tLoss = 1.1810727705010775\n",
            "\tAccuracy = 0.7234576494724502\n",
            "\tF1 Score = 0.6280197652357098\n",
            "Epoch 26:\n",
            "\tLoss = 1.1808370463593763\n",
            "\tAccuracy = 0.7236408264947245\n",
            "\tF1 Score = 0.6300312598190752\n",
            "Epoch 27:\n",
            "\tLoss = 1.179674646359675\n",
            "\tAccuracy = 0.7249963364595545\n",
            "\tF1 Score = 0.6307862584134306\n",
            "Epoch 28:\n",
            "\tLoss = 1.179495813418944\n",
            "\tAccuracy = 0.725078766119578\n",
            "\tF1 Score = 0.6333825804649429\n",
            "Epoch 29:\n",
            "\tLoss = 1.1775865758848918\n",
            "\tAccuracy = 0.7270570779601406\n",
            "\tF1 Score = 0.6358051581287943\n",
            "Epoch 30:\n",
            "\tLoss = 1.1770543987837654\n",
            "\tAccuracy = 0.727496702813599\n",
            "\tF1 Score = 0.6366595293289514\n",
            "Epoch 31:\n",
            "\tLoss = 1.176082387339468\n",
            "\tAccuracy = 0.7286415592028136\n",
            "\tF1 Score = 0.6392334656425198\n",
            "Epoch 32:\n",
            "\tLoss = 1.175056447317564\n",
            "\tAccuracy = 0.7295574443141852\n",
            "\tF1 Score = 0.6385077291275302\n",
            "Epoch 33:\n",
            "\tLoss = 1.1756388958006363\n",
            "\tAccuracy = 0.72895296014068\n",
            "\tF1 Score = 0.6389593250771197\n",
            "Epoch 34:\n",
            "\tLoss = 1.1742006516540455\n",
            "\tAccuracy = 0.7304916471277842\n",
            "\tF1 Score = 0.6390687983620875\n",
            "Epoch 35:\n",
            "\tLoss = 1.1730162534177093\n",
            "\tAccuracy = 0.7316731389214537\n",
            "\tF1 Score = 0.6417703945745772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hgbbXz7mz1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents2 = []\n",
        "#convert data into format for the previous labs\n",
        "\n",
        "#use full dataset\n",
        "for i in range(test.shape[0]):\n",
        " tmpWords = word_tokenize(test['Phrase'][i])\n",
        " documents2.append((tmpWords, test['Sentiment'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqrtwNk8m4sD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "81864f40-f968-454c-f8f6-c4072dc73f2d"
      },
      "source": [
        "random.seed(9001)\n",
        "random.shuffle(documents2)\n",
        "print(documents2[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['One', 'suspects', 'that', 'Craven', 'endorses', 'They', 'simply', 'because', 'this', 'movie', 'makes', 'his', 'own', 'look', 'much', 'better', 'by', 'comparison', '.'], 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtYgMliIm5Ft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8ee6057-54fd-4e1d-cd67-1576ebf2b627"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = True\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "\n",
        "for l in range(len(documents2)):\n",
        "  label = documents2[l][1]\n",
        "  tmpReview = []\n",
        "  for w in documents2[l][0]:\n",
        "    newWord = w\n",
        "    if remove_stopwords and (w in stopwords_en):\n",
        "      continue\n",
        "    if removePuncs and (w in punctuations):\n",
        "      continue\n",
        "    if useStemming:\n",
        "      newWord = porter.stem(newWord)\n",
        "      # newWord = lancaster.stem(newWord)\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord)\n",
        "  documents2[l] = (' '.join(tmpReview), label)\n",
        "print(documents2[2])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('jonah', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9mzo1LonDnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data2 = pd.DataFrame(documents2, columns=['Phrase', 'Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gCNbeJnpvsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "49c63d15-e3da-4bb6-c3e2-2c8d36a4e268"
      },
      "source": [
        "test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Irwins ' scenes are fascinating ; the movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>never quite gel</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>look behind the curtain that separates comics ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>that has bucked the odds to emerge as an exqui...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>of dramatic urgency</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46813</th>\n",
              "      <td>as a serious drama about spousal abuse</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46814</th>\n",
              "      <td>The elements were all there but lack of a pysc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46815</th>\n",
              "      <td>routinely</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46816</th>\n",
              "      <td>to films which will cause loads of irreparable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46817</th>\n",
              "      <td>lower</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46818 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Phrase  Sentiment\n",
              "0      The Irwins ' scenes are fascinating ; the movi...          0\n",
              "1                                        never quite gel          1\n",
              "2      look behind the curtain that separates comics ...          2\n",
              "3      that has bucked the odds to emerge as an exqui...          4\n",
              "4                                    of dramatic urgency          2\n",
              "...                                                  ...        ...\n",
              "46813             as a serious drama about spousal abuse          3\n",
              "46814  The elements were all there but lack of a pysc...          1\n",
              "46815                                          routinely          2\n",
              "46816  to films which will cause loads of irreparable...          1\n",
              "46817                                              lower          2\n",
              "\n",
              "[46818 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrG-sHsMpKdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "dd4c9d89-79ad-43aa-d7c1-c3456f057521"
      },
      "source": [
        "all_data2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>perfect face play handsom blank yearn find</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one suspect craven endors they simpli movi mak...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jonah</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>idol</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cold dead</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46813</th>\n",
              "      <td>basic</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46814</th>\n",
              "      <td>murphi wilson actual make pretti good team ......</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46815</th>\n",
              "      <td>ticket</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46816</th>\n",
              "      <td>use make movi also sometim still made</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46817</th>\n",
              "      <td>memori lane</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46818 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Phrase  Sentiment\n",
              "0             perfect face play handsom blank yearn find          2\n",
              "1      one suspect craven endors they simpli movi mak...          1\n",
              "2                                                  jonah          2\n",
              "3                                                   idol          3\n",
              "4                                              cold dead          1\n",
              "...                                                  ...        ...\n",
              "46813                                              basic          2\n",
              "46814  murphi wilson actual make pretti good team ......          2\n",
              "46815                                             ticket          2\n",
              "46816              use make movi also sometim still made          2\n",
              "46817                                        memori lane          2\n",
              "\n",
              "[46818 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNHw91b_gCBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 10000, stop_words=\"english\", ngram_range=(1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMDoTQZor5f-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "980057d9-568e-45b0-dfc3-8d63096f733a"
      },
      "source": [
        "x_test = vectorizer.fit_transform(all_data2[\"Phrase\"])\n",
        "y_test = all_data2[\"Sentiment\"]\n",
        "\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np=np.array(y_test)\n",
        "\n",
        "# Test the model\n",
        "inputs = torch.from_numpy(x_test_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_test_np.reshape(y_test_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "# Create DataLoader instance to work with batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "# Cycle through batches and get average loss and other metrics\n",
        "avg_loss, avg_accu, avg_prec, avg_rec = model_loss(model, loader)\n",
        "\n",
        "# Get f1 score\n",
        "f1 = (2 * (avg_rec * avg_prec)/(avg_rec + avg_prec))\n",
        "\n",
        "# Printing the loss and other metrics\n",
        "print(\"Loss = \" + str(avg_loss) +\n",
        "    \"\\nTesting Accuracy = \" + str(avg_accu) + \n",
        "      \"\\nTesting F1 Score = \" + str(f1))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 1.4382318983339284\n",
            "Testing Accuracy = 0.46579623287671235\n",
            "Testing F1 Score = 0.21821134511794385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea0HARutr-hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "da4f1a29-0403-45bc-9da7-43927a6932f2"
      },
      "source": [
        "import matplotlib.pyplot as plt# Create the  and show it# For the predictions, since they're on the GPU, we need to move them to the CPU\n",
        "\n",
        "\n",
        "plt.plot(e1,l1, color='red', label= \"L1Loss\")\n",
        "plt.plot(e1,f1plot, color='yellow', label= \"F1Score\")\n",
        "plt.plot(e1,a1, color='blue', label= \"Accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcdd81b8940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgp0EZEs8f99GHORqW6AXgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWsME0lT0pYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}